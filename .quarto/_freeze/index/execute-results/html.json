{
  "hash": "6fb071ee43cbcbb2b9dcaa321ff52af3",
  "result": {
    "engine": "knitr",
    "markdown": "::: {.cell}\n\n:::\n\n\n\n\n## (Why) only us?\n\n::: columns\n:::: {.column width=65%}\n\n* Humans develop linguistic abilities unparalelled to non-human animals\n* But some animals show certain ability to process some aspects of language [e.g., @toro2016something]\n* Shared mechanisms: [entry gate to human language acquisition]{style=\"background-color: #e3e1e1;\"}?\n\n::::\n:::: {.column width=35%}\n[![](assets/why-only-us.jpg){width=50%}](https://mitpress.mit.edu/9780262533492/why-only-us/)\n::::\n:::\n\n::: box\n**Gates to Language (GALA) ERC project (Chiara Santolin)**\n:::\n\n::: {.notes}\n- Most animals develop sophisticated communicative systems\n- Only humans develop language (compositional, recursive, symbolic, etc.)\n- Some animals show near-human-level abilities in some of those domains\n- We share with non-human animals some mechanisms that support language\n- Are those mechanisms the entry gate to human language acquisition?\n- In this ERC-StG awareded to Chiara Santolin, we are going to investigate the possible role of two of those mechanisms on early language acquisition\n:::\n\n---\n\n## Discrete units in the continuous speech signal\n\n![From @meyer2018neural.](assets/multilevel.jpg)\n\n::: {.notes}\n- We are focusing on one of the first and most critical steps in language acquisition: chunking the continuous speech stream into discrete, linguistically relevant units.\n:::\n\n## The syllable: a privileged linguistic unit?\n\nNewborns (and adults) preferentially parse the speech signal into [syllable-sized units]{style=\"background-color: #e3e1e1;\"} [e.g, @bijeljac19934; @flo2022sleeping; @luo2007phase; @jusczyk1987representation; @bertoncini1988investigation]\n\n![From @flo2022sleeping.](assets/entrainment.png)\n\n::: {.notes}\n- Syllables seem to be specially important during the first stages of language acquisition\n- Newborns preferentially parse speech into syllables (as opposed to individual phonemes, words, or phrases)\n- What makes syllables so special? \n:::\n\n## Syllabic structure\n\n::: {.columns}\n::: {.column width=\"40%\"}\n![](assets/structure.png)\n:::\n::: {.column width=\"60%\"}\n:::\n:::\n\n::: {.notes}\n- The universal structure of a syllable is made of three elements\n- A mandatory nucleus: this is a high-sonority speech sound (predominantly a vowel)\n- Perhaps an onset, made of one or more consonants\n- Perhaps a coda, made of one or more consonant\n:::\n\n## Syllabic structure\n\n::: {.columns}\n::: {.column width=\"40%\"}\n![](assets/structure.png)\n:::\n::: {.column width=\"60%\"}\n|Structure |Onset  |Nucleus  |Coda  |\n|----------|:-----:|:-------:|:----:|\n| V        |       |a        |      |\n| CV       | t     |a        |      |\n| CVC      | t     |a        |n     |\n| VC       |       |a        |n     |\n:::\n:::\n\n::: {.notes}\n- Same examples of syllables\n:::\n\n\n## Language-specific constraints to syllabic structure\n\n| Structure | Japanese     | Spanish          | English         |\n|-----------|--------------|------------------|-----------------|\n|V          | [u]{style=\"background-color: #e3e1e1;\"}.mi     | [o]{style=\"background-color: #e3e1e1;\"}.jo         | [a]{style=\"background-color: #e3e1e1;\"}.ny        |\n|CV         | [ya]{style=\"background-color: #e3e1e1;\"}.ma.ha | [ca]{style=\"background-color: #e3e1e1;\"}.sa        | [fai]{style=\"background-color: #e3e1e1;\"}.ry      | \n|CVC        | [hon]{style=\"background-color: #e3e1e1;\"}.da   | [rin]{style=\"background-color: #e3e1e1;\"}.cón      | [con]{style=\"background-color: #e3e1e1;\"}.trol    |\n|CCVC       |              | [fres]{style=\"background-color: #e3e1e1;\"}.co      | [fresh]{style=\"background-color: #e3e1e1;\"}       |\n|CCVCC      |              | [trans]{style=\"background-color: #e3e1e1;\"}.por.te | [shrink]{style=\"background-color: #e3e1e1;\"}     |\n|CCCVCCC    |              |                  | [strengths]{style=\"background-color: #e3e1e1;\"}   |\n\n: Adapted from Özer (2024).\n\n::: {.notes}\n- Not all syllabic structures are possible in all languages\n- Some languages impose stricter phonotactical constraints on the specific sounds and number of sounds that can occur at onset or coda\n:::\n\n\n## Universal constraints to syllabic structure\n\nCan you chunk this word into syllables?\n\n> /likla/\n\n. . .\n\n::: box\n**Maximal Onset Principle (MOP)**:\n\nConsonants are preferably grouped at syllabic onset\n:::\n\n* [MOP+]{style=\"background-color: #ea6212; color: white\"}: CV.CCV - /li.kla/\n* [MOP-]{style=\"background-color: #781478; color: white\"}: CVC.CV - /lik.la/\n\n::: {.notes}\n- However, some constraints to syllabic structure seem to be universal\n- Universal: most, if not all languages, show a preference for following some specific constraints\n- The aim of this project is to investigate the possible role of these universals as an early mechanism for syllabification\n:::\n\n## Universal constraints to syllabic structure\n\nWhich of these syllables sound good to you?\n\n> /blif/ vs. /lbif/\n\n. . .\n\n::: box\n**Sonority Sequencing Principle (SSP)**:\n\nSonority increases at onset, peaks at nucleus, decreases in coda\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/fig-ssp-blif-1.png){#fig-ssp-blif width=4800}\n:::\n:::\n\n\n\n::: {.notes}\n- However, some constraints to syllabic structure seem to be universal\n- Universal: most, if not all languages, show a preference for following some specific constraints\n- Both universals determine to a large extent the position of syllabic boundaries, and the order of the segments that make up a syllable\n:::\n\n\n\n## The Gates to Language (GALA) project\n\n* Do newborns use MOP and SSP to detect syllable boundaries?\n\n> Syllables as an entry gate to language\n\n. . .\n\n* Are these mechanisms shared with non-human animals? (e.g., production)\n\n> Syllables as philogenetically relevant linguistic units\n\n. . .\n\n\n::: {.notes}\n- The aim of this project is to investigate:\n  1) The possible role of these universals as an early mechanism for syllabification\n  2) The extent to which these mechanisms are shared with other non-human animals\n- The Maximal Onset Principle (MOP) and the Sonority Sequencing Principle (SSP)\n- We will also investigate whether a non-human animal species (Long-Evans rats), which do not develop language, are also sensitive to any of these principles\n:::\n\n## The Gates to Language (GALA) project\n\nTwo lines of research: MOP and SSP\n\n* Neonates (fNIRS)\n* Infants (fNIRS, eye-tracking, behaviour)\n* Adults (behavioural)\n* Long-Evans rats (behavioural)\n\n\n# Maximal Onset Principle (MOP)\n\nResearch line 1\n\n## Study 1: are newborns sensitive to (violations of) the MOP?\n\n::: box\nConsonants are preferably grouped at syllable onset.\n:::\n\n* [MOP+]{style=\"background-color: #ea6212; color: white\"}: CV.CCV - /li.kla/  \n* [MOP-]{style=\"background-color: #781478; color: white\"}: CVC.CV - /lik.la/\n\n::: {.notes}\n- The first universal we will investigate is the Maximal Onset Principle (MOP)\n- This principle states that \"consonants\" are preferably grouped at syllable onset\n- This principle constrains the position of syllabic boundaries\n- If neonates are sensitive to violations of the MOP, it would suggest that they might be using the MOP to syllabify the speech signal from birth\n:::\n\n\n## Participants\n\n* Hearing, full term neonates (fNIRS) and 6-10 mo infants (fNIRS + behavioural)\n* Born/living in the Metropolitan Area of Barcelona (Spain)\n* Mostly Catalan and/or Spanish linguistic background\n\n::: {.notes}\n- We will run an experimental series that involves neonates and infants\n- Neonates will be tested using fNIRS, while infants will be tested using fNIRS and behavioural tasks (like the HeadTurn Preference Procedure)\n- I will focus on the fNIRS testing of neonates and infants, as they follow the same task design\n- Ideally, we'd like to test up to 50 participants per experiment, although power analysis is pending\n- Most of our participants will have a Catalan and/or Spanish background\n:::\n\n\n## fNIRS setup\n\n* NIRSport2 (NIRx), CW 760 nm & 850 nm\n* Sampling frequency 20.345 Hz (~0.05 s samples)\n* NIRScap: 8 channels LH, 8 channels RH\n* ROIs: L and R temporal regions\n* Crib testing in neonates, parents' lap in infants (watching cartoons)\n* MNE-NIRS (Python): (1) OD, (2) motion correction (TDDR), (3) band-pass filtering, (4) block segmentation, (5) block averaging, (6) block rejection, (7) participant rejection.\n\n## Task design (fNIRS block design)\n\n**Familiarisation/discrimination task:**\n\n1) Familiarise participants with disyllabic CVCCV words\n    - 10 blocks, 6 words each\n\n. . .\n\n2) Test discrimination of artificially segmented familiar words as [MOP+]{style=\"background-color: #ea6212; color: white\"} (CV.CCV) vs. [MOP-]{style=\"background-color: #781478; color: white\"} (CVC.CV):\n    - 4 alternating blocks ([MOP+]{style=\"background-color: #ea6212; color: white\"}/[MOP-]{style=\"background-color: #781478; color: white\"})\n    - 2 non-alternating blocks ([MOP+]{style=\"background-color: #ea6212; color: white\"})\n    - 2 non-alternating blocks ([MOP-]{style=\"background-color: #781478; color: white\"})\n\n## Stimuli\n\n::: box\n**CVCCV words**: Onset + Vowel + Consonant cluster (CC) + Vowel\n:::\n\n. . .\n\n::: columns\n:::: {.column width=\"40%\"}\n| [MOP+]{style=\"background-color: #ea6212; color: white\"} (CV.CCV) | [MOP-]{style=\"background-color: #781478; color: white\"} (CVC.CV)|\n|:-------------:|:------------:|\n|li.kla         |lik.la        |\n|ro.tri         |rot.ri        |\n|po.glu         |pog.lu        |\n\n::::\n:::: {.column width=\"60%\"}\nSome constraints:\n\n- [MOP+]{style=\"background-color: #ea6212; color: white\"}: CC follows **SSP**\n- [MOP+]{style=\"background-color: #ea6212; color: white\"}: CC is phonotactical at onset in speakers' and participants' native language(s)\n- [MOP-]{style=\"background-color: #781478; color: white\"}: C is allowed in coda in speakers' and participants' native language(s)\n::::\n:::\n\n---\n\n### Familiarisation phase\n\n![](assets/fam-mop.png){width=100%}\n\n---\n\n### Test phase\n\n![](assets/test-mop.png){width=100%}\n\n## Questions\n\n- Natural speaker or synthesised speech (e.g., MBROLA)?\n- Variability vs. repetition? More vs. less consonant clusters\n- Linguistic experience at 8-12 months?\n- Familiarisation phase: how many blocks is enough/too much?\n- fNIRS recording during familiarisation? (e.g., capping in between phases)\n\n# Sonority Sequencing Principle (SSP)\n\nResearch line 2\n\n## Study 2: are newborns sensitive to (violations of) the SSP?\n\n::: columns\n:::: {.column width=\"40%\" .incremental}\n\nSyllables are predominantly a production unit: they result from a \"single effort or impulse of the voice.\" [@whitney1874oriental]\n\n> In a syllable, sonority increases toward the peak and decreases toward the margins. [@morelli2003relative]\n\n::::\n:::: {.column width=\"60%\"}\nThe biomecanics of the phonatory system constrain the properties of the acoustic signal of (exhalated) animal vocalisations.\n\n![From @tierney2011motor](assets/birds.png)\n::::\n:::\n\n\n\n## Study 2: are newborns sensitive to (violations of) the SSP?\n\n[Proposal]{style=\"background-color: #e3e1e1;\"}:\n\n1) Syllables are biologically relevant linguistic units\n2) Language processing at birth is constrained by phylogenetically acquired perception mechanisms (e.g., SSP)\n\n. . .\n\n[Hypotheses]{style=\"background-color: #e3e1e1;\"}:\n\n* Neonates are sensitive to (violations of) the SSP\n* Long-Evans rats are sensitive to (violations of) the SSP\n* This sensitivity plays a role beyond language (non-linguistic sounds)\n\n---\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sonority Sequencing Principle. Sonority values from @parker201149](index_files/figure-revealjs/fig-ssp-bran-1.png){#fig-ssp-bran width=4800}\n:::\n:::\n\n\n\n## Sonority Sequencing Principle (SSP)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sonority profile of the syllable 'bran'](index_files/figure-revealjs/fig-sspl-bran-grid-1.png){#fig-sspl-bran-grid width=8000}\n:::\n:::\n\n\n\n## Sonority Sequencing Principle (SSP)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sonority Sequencing Principle. Sonority values from @parker201149](index_files/figure-revealjs/fig-ssp-lbif-1.png){#fig-ssp-lbif width=8000}\n:::\n:::\n\n\n\n## Sonority Sequencing Principle (SSP)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Sonority profile of the syllable 'lbif'](index_files/figure-revealjs/fig-sspl-lbif-grid-1.png){#fig-sspl-lbif-grid width=8000}\n:::\n:::\n\n\n\n## Participants\n\n* Hearing, full term neonates (fNIRS) and 6-10 mo infants (fNIRS + behavioural)\n* Born/living in the Metropolitan Area of Barcelona (Spain)\n* Mostly Catalan and/or Spanish linguistic background\n\n## Stimuli\n\nFrom @schutsch2024sensory:\n\n* List of [SSP+]{style=\"background-color: #ea6212; color: white\"} (e.g., *blif* and [SSP-]{style=\"background-color: #781478; color: white\"} (e.g., *lbif*) CCVC syllables\n* For each syllable:\n  - Chunk acoustic signal into segments (x4 phonemes)\n  - Calculate average F0/F1/F2 of each segment\n  - Synthesise pure tone based on extracted pitch for each segment\n  - Apply amplitude envelope of original audio\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<audio controls=\"\">\n<source src=\"assets/enveloped_click_bran.wav\" type=\"audio/wav\"/>\n</audio>\n```\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<audio controls=\"\">\n<source src=\"assets/enveloped_click_lbif.wav\" type=\"audio/wav\"/>\n</audio>\n```\n\n:::\n:::\n\n\n\n## Task design (fNIRS block design)\n\n1. Test phase:\n  - 4 blocks of artificially segmented words: 1 Non-alt/[SSP+]{style=\"background-color: #ea6212; color: white\"}, 1 Non-alt/[SSP-]{style=\"background-color: #781478; color: white\"}, 2 Alt (20-22s silence between blocks)\n  - 12 words different words in each block (0.5-1.5s silence between words)\n\n---\n\n![](assets/test-ssp.png){width=100%}\n\n---\n\n## Questions\n\n- Discriminability of [SSP+]{style=\"background-color: #ea6212; color: white\"}/[SSP-]{style=\"background-color: #781478; color: white\"}: amplitude vs. pitch salience?\n    + Adult experiment, artificial neural network?\n    \n## {background-image=\"assets/thanks.png\"}\n\n## References\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}