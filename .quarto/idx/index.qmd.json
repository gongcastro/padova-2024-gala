{"title":"Mechanisms for parsing speech into syllables in early infancy","markdown":{"headingText":"(Why) only us?","containsRefs":false,"markdown":"```{r setup}\nlibrary(tibble)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(ggdist)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(praatpicture)\nlibrary(showtext)\n\nfont_add_google(\"Roboto Condensed\", \"Roboto\")\nwindowsFonts(\"Roboto Condensed\" = windowsFont(\"Roboto Condensed\"))\n\nhtml_tag_audio <- function(file, type = c(\"wav\")) {\n  type <- match.arg(type)\n  htmltools::tags$audio(\n    controls = \"\",\n    htmltools::tags$source(\n      src = file,\n      type = glue::glue(\"audio/{type}\", type = type)\n    )\n  )\n}\n\nclrs <- c(\"#ea6212\", \"#ff001e\", \"#781478\")\n```\n\n\n\n::: columns\n:::: {.column width=65%}\n\n* Humans develop linguistic abilities unparalelled to non-human animals\n* But some animals show certain ability to process some aspects of language [e.g., @toro2016something]\n* Shared mechanisms: [entry gate to human language acquisition]{style=\"background-color: #ff001e; color: white\"}?\n\n::::\n:::: {.column width=35%}\n[![](assets/why-only-us.jpg){width=50%}](https://mitpress.mit.edu/9780262533492/why-only-us/)\n::::\n:::\n\n::: box\n**Gates to Language (GALA) ERC project (Chiara Santolin)**\n:::\n\n::: {.notes}\n- Most animals develop sophisticated communicative systems\n- Only humans develop language (compositional, recursive, symbolic, etc.)\n- Some animals show near-human-level abilities in some of those domains\n- We share with non-human animals some mechanisms that support language\n- Are those mechanisms the entry gate to human language acquisition?\n- In this ERC-StG awareded to Chiara Santolin, we are going to investigate the possible role of two of those mechanisms on early language acquisition\n:::\n\n---\n\n## Discrete units in the continuous speech signal\n\n![From @meyer2018neural.](assets/multilevel.jpg)\n\n::: {.notes}\n- We are focusing on one of the first and most critical steps in language acquisition: chunking the continuous speech stream into discrete, linguistically relevant units.\n:::\n\n## The syllable: a privileged lingusitic unit?\n\nNewborns (and adults) preferentially parse the speech signal into [syllable-sized units]{style=\"background-color: #ff001e; color: white\"} [e.g, @bijeljac19934; @flo2022sleeping; @luo2007phase; @jusczyk1987representation; @bertoncini1988investigation]\n\n![From @flo2022sleeping.](assets/entrainment.png)\n\n::: {.notes}\n- Syllables seem to be specially important during the first stages of language acquisition\n- Newborns preferentially parse speech into syllables (as opposed to individual phonemes, words, or phrases)\n- What makes syllables so special? \n:::\n\n## Syllabic structure\n\n::: {.columns}\n::: {.column width=\"40%\"}\n![](assets/structure.png)\n:::\n::: {.column width=\"60%\"}\n:::\n:::\n\n::: {.notes}\n- The universal structure of a syllable is made of three elements\n- A mandatory nucleus: this is a high-sonority speech sound (predominantly a vowel)\n- Perhaps an onset, made of one or more consonants\n- Perhaps a coda, made of one or more consonant\n:::\n\n## Syllabic structure\n\n::: {.columns}\n::: {.column width=\"40%\"}\n![](assets/structure.png)\n:::\n::: {.column width=\"60%\"}\n|Structure |Onset  |Nucleus  |Coda  |\n|----------|:-----:|:-------:|:----:|\n| V        |       |a        |      |\n| CV       | t     |a        |      |\n| CVC      | t     |a        |n     |\n| VC       |       |a        |n     |\n:::\n:::\n\n::: {.notes}\n- Same examples of syllables\n:::\n\n\n## Language-specific constraints to syllabic structure\n\n| Structure | Japanese     | Spanish          | English         |\n|-----------|--------------|------------------|-----------------|\n|V          | [u]{style=\"background-color: #e3e1e1;}.mi     | [o]{style=\"background-color: #e3e1e1;}.jo         | [a]{style=\"background-color: #e3e1e1;}.ny        |\n|CV         | [ya]{style=\"background-color: #e3e1e1;}.ma.ha | [ca]{style=\"background-color: #e3e1e1;}.sa        | [fai]{style=\"background-color: #e3e1e1;}.ry      | \n|CVC        | [hon]{style=\"background-color: #e3e1e1;}.da   | [rin]{style=\"background-color: #e3e1e1;}.cón      | [con]{style=\"background-color: #e3e1e1;}.trol    |\n|CCVC       |              | [fres]{style=\"background-color: #e3e1e1;}.co      | [fresh]{style=\"background-color: #e3e1e1;}       |\n|CCVCC      |              | [trans]{style=\"background-color: #e3e1e1;}.por.te | [shrink]{style=\"background-color: #e3e1e1;}     |\n|CCCVCCC    |              |                  | [strengths]{style=\"background-color: #e3e1e1;}   |\n\n: Adapted from Özer (2024).\n\n::: {.notes}\n- Not all syllabic structures are possible in all languages\n- Some languages impose stricter phonotactical constraints on the specific sounds and number of sounds that can occur at onset or coda\n:::\n\n\n## Universal constraints to syllabic structure\n\nCan you chunk this word into syllables?\n\n> /likla/\n\n. . .\n\n::: box\n**Maximal Onset Principle (MOP)**:\n\nConsonants are preferably grouped at syllabic onset\n:::\n\n* [MOP+]{style=\"background-color: #ea6212; color: white\"}: CV.CCV - /li.kla/\n* [MOP-]{style=\"background-color: #781478; color: white\"}: CVC.CV - /lik.la/\n\n::: {.notes}\n- However, some constraints to syllabic structure seem to be universal\n- Universal: most, if not all languages, show a preference for following some specific constraints\n- The aim of this project is to investigate the possible role of these universals as an early mechanism for syllabification\n:::\n\n## Universal constraints to syllabic structure\n\nWhich of these syllables sound good to you?\n\n> /blif/ vs. /lbif/\n\n. . .\n\n::: box\n**Sonority Sequencing Principle (SSP)**:\n\nSonority increases at onset, peaks at nucleus, decreases in coda\n:::\n\n```{r fig-ssp-blif}\n#| label: fig-ssp-blif\n#| fig-height: 1.5\n#| fig-width: 6\ntribble(\n  ~position, ~phoneme, ~sonority,\n  \"Onset\", \"b\", 4,\n  \"Onset\", \"l\", 10,\n  \"Nucleus\", \"i\", 17,\n  \"Coda\", \"f\", 7\n) |>\n  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>\n  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +\n  geom_col(colour = \"white\") +\n  geom_line(aes(group = 1)) +\n  geom_point(show.legend = TRUE) +\n  tribble(\n    ~position, ~phoneme, ~sonority,\n    \"Onset\", \"l\", 10,\n    \"Onset\", \"b\", 4,\n    \"Nucleus\", \"i\", 15,\n    \"Coda\", \"f\", 7\n  ) |>\n  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>\n  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +\n  geom_col(colour = \"white\") +\n  geom_line(aes(group = 1)) +\n  geom_point(show.legend = FALSE) +\n  theme(axis.title.y = element_blank()) +\n  plot_layout(nrow = 1, guides = \"collect\") &\n  labs(x = \"Phoneme\", y = \"Sonority Index\") &\n  scale_fill_manual(values = clrs) &\n  theme_ggdist(base_family = windowsFonts()$`Roboto Condensed`) &\n  theme(\n    legend.position = \"right\",\n    axis.title.x = element_blank(),\n    legend.title = element_blank(),\n    plot.background = element_rect(fill = NA)\n  )\n```\n\n::: {.notes}\n- However, some constraints to syllabic structure seem to be universal\n- Universal: most, if not all languages, show a preference for following some specific constraints\n- Both universals determine to a large extent the position of syllabic boundaries, and the order of the segments that make up a syllable\n:::\n\n\n\n## The Gates to Language (GALA) project\n\n* Do newborns use MOP and SSP to detect syllable boundaries?\n* Are these mechanisms shared with non-human animals? (e.g., production)\n\n> Are syllables a biologically meaninful linguistic unit?\n\n::: {.notes}\n- The aim of this project is to investigate:\n  1) The possible role of these universals as an early mechanism for syllabification\n  2) The extent to which these mechanisms are shared with other non-human animals\n- The Maximal Onset Principle (MOP) and the Sonority Sequencing Principle (SSP)\n- We will also investigate whether a non-human animal species (Long-Evans rats), which do not develop language, are also sensitive to any of these principles\n:::\n\n\n# Maximal Onset Principle (MOP)\n\nResearch line 1: neonates, infants, Long-Evans rats\n\n## Study 1: are newborns sensitive to (violations of) the MOP?\n\n::: box\nConsonants are preferably grouped at syllable onset.\n:::\n\n* [MOP+]{style=\"background-color: #ea6212; color: white\"}: CV.CCV - /li.kla/  \n* [MOP-]{style=\"background-color: #781478; color: white\"}: CVC.CV - /lik.la/\n\n::: {.notes}\n- The first universal we will investigate is the Maximal Onset Principle (MOP)\n- This principle states that \"consonants\" are preferably grouped at syllable onset\n- This principle constrains the position of syllabic boundaries\n- If neonates are sensitive to violations of the MOP, it would suggest that they might be using the MOP to syllabify the speech signal from birth\n:::\n\n\n## Participants\n\n* Hearing, full term neonates (fNIRS) and 6-10 mo infants (fNIRS + behavioural)\n* Born/living in the Metropolitan Area of Barcelona (Spain)\n* Mostly Catalan and/or Spanish linguistic background\n\n::: {.notes}\n- We will run an experimental series that involves neonates and infants\n- Neonates will be tested using fNIRS, while infants will be tested using fNIRS and behavioural tasks (like the HeadTurn Preference Procedure)\n- I will focus on the fNIRS testing of neonates and infants, as they follow the same task design\n- Ideally, we'd like to test up to 50 participants per experiment, although power analysis is pending\n- Most of our participants will have a Catalan and/or Spanish background\n:::\n\n\n## fNIRS setup\n\n* NIRSport2 (NIRx), NIRScap\n* Sampling frequency 20.345 Hz (~0.05 s samples)\n* CW 760 nm & 850 nm\n* 8 channels LH, 8 channels RH\n* ROIs: L and R temporal regions\n* Crib testing in neonates, parents' lap in infants (watching cartoons)\n\n## Task design (fNIRS block design)\n\n**Familiarisation/discrimination task:**\n\n1) Familiarise participants with disyllabic CVCCV words\n    - 10 blocks, 6 words each\n2) Test discrimination of artificially segmented familair words as [MOP+]{style=\"background-color: #ea6212; color: white\"} (CV.CCV) vs. [MOP-]{style=\"background-color: #781478; color: white\"} (CVC.CV):\n    - 4 alternating blocks ([MOP+]{style=\"background-color: #ea6212; color: white\"}/[MOP-]{style=\"background-color: #781478; color: white\"})\n    - 2 non-alternating blocks ([MOP+]{style=\"background-color: #ea6212; color: white\"})\n    - 2 non-alternating blocks ([MOP-]{style=\"background-color: #781478; color: white\"})\n\n## Stimuli\n\n::: box\n**CVCCV words**: Onset + Vowel + Consonant cluster (CC) + Vowel\n:::\n\n::: columns\n:::: {.column width=\"40%\"}\n| [MOP+]{style=\"background-color: #ea6212; color: white\"} (CV.CCV) | [MOP-]{style=\"background-color: #781478; color: white\"} (CVC.CV)|\n|:-------------:|:------------:|\n|li.kla         |lik.la        |\n|ro.tri         |rot.ri        |\n|po.glu         |pog.lu        |\n\n::::\n:::: {.column width=\"60%\"}\nSome constraints:\n\n- [MOP+]{style=\"background-color: #ea6212; color: white\"}: CC follows **SSP**\n- [MOP+]{style=\"background-color: #ea6212; color: white\"}: CC is phonotactical at onset in speakers' and participants' native language(s)\n- [MOP-]{style=\"background-color: #781478; color: white\"}: C is allowed in coda in speakers' and participants' native language(s)\n::::\n:::\n\n---\n\n### Familiarisation phase\n\n![](assets/fam-mop.png){width=100%}\n\n---\n\n### Test phase\n\n![](assets/test-mop.png){width=100%}\n\n## Questions\n\n- Natural speaker or synthesised speech (e.g., MBROLA)?\n- Variability vs. repetition? More vs. less consonant clusters\n- Linguistic experience at 8-12 months?\n- Familiarisation phase: how many blocks is enough/too much?\n- fNIRS recording during familiarisation? (e.g., capping in between phases)\n\n# Sonority Sequencing Principle (SSP)\n\nResearch line 2: neonates, infants, Long-Evans rats\n\n## Study 2: are newborns sensitive to (violations of) the SSP?\n\nSyllables are predominantly a production unit: they result from a \"single effort or impulse of the voice.\" [@whitney1874oriental]\n\n> In a syllable, sonority increases toward the peak and decreases toward the margins. [@morelli2003relative]\n\n## Study 2: are newborns sensitive to (violations of) the SSP?\n\n::: columns\n:::: {.column width=\"40%\"}\n* Most animal vocalisations follow the SSP\n* Evolutionary relevance\n* Ancestral, inherited mechanism for perception?\n* Does SSP play a role in non-linguistic sound perception?\n::::\n:::: {.column width=\"60%\"}\n![From @tierney2011motor](assets/birds.png)\n::::\n:::\n\n---\n\n```{r fig-ssp-bran}\n#| label: fig-ssp-bran\n#| fig-cap: \"Sonority Sequencing Principle. Sonority values from @parker201149\"\n#| fig-height: 4\n#| fig-width: 6\ntribble(\n  ~position, ~phoneme, ~sonority,\n  \"Onset\", \"b\", 1,\n  \"Onset\", \"ɾ\", 10,\n  \"Nucleus\", \"a\", 17,\n  \"Coda\", \"n\", 7\n) |>\n  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>\n  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +\n  geom_col(colour = \"white\") +\n  geom_line(aes(group = 1)) +\n  geom_point(show.legend = FALSE) +\n  labs(x = \"Phoneme\", y = \"Sonority Index\") +\n  scale_fill_manual(values = clrs) +\n  theme_ggdist() +\n  theme(\n    legend.position = \"top\",\n    axis.title.x = element_blank(),\n    legend.title = element_blank(),\n    plot.background = element_rect(fill = NA)\n  )\n```\n\n## Sonority Sequencing Principle (SSP)\n\n```{r fig-ssp-bran-grid}\n#| label: fig-sspl-bran-grid\n#| fig-cap: \"Sonority profile of the syllable 'bran'\"\npraatpicture::praatpicture(\n  \"assets/bran.wav\",\n  intensity_plotOnSpec = TRUE,\n  intensity_color = RColorBrewer::brewer.pal(3, \"Reds\")[2],\n  font.axis = 2,\n  spec_colors = RColorBrewer::brewer.pal(9, \"Greys\")[1:7],\n  font = 2,\n  pitch_freqRange = c(0, 700),\n  proportion = c(50, 25, 25),\n  family = \"fira\",\n  lwd = 2,\n  wave_color = RColorBrewer::brewer.pal(3, \"Reds\")[2],\n)\n```\n\n## Sonority Sequencing Principle (SSP)\n\n```{r fig-ssp-lbif}\n#| label: fig-ssp-lbif\n#| fig-cap: \"Sonority Sequencing Principle. Sonority values from @parker201149\"\ntribble(\n  ~position, ~phoneme, ~sonority,\n  \"Onset\", \"l\", 9,\n  \"Onset\", \"b\", 1,\n  \"Nucleus\", \"i\", 15,\n  \"Coda\", \"f\", 3\n) |>\n  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>\n  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +\n  geom_col(colour = \"white\") +\n  geom_line(aes(group = 1)) +\n  geom_point(show.legend = TRUE) +\n  labs(x = \"Phoneme\", y = \"Sonority Index\") +\n  scale_fill_manual(values = clrs) +\n  theme_ggdist() +\n  theme(\n    legend.position = \"top\",\n    axis.title.x = element_blank(),\n    legend.title = element_blank(),\n    plot.background = element_rect(fill = NA)\n  )\n```\n\n## Sonority Sequencing Principle (SSP)\n\n```{r fig-ssp-lbif-grid}\n#| label: fig-sspl-lbif-grid\n#| fig-cap: \"Sonority profile of the syllable 'lbif'\"\npraatpicture::praatpicture(\n  \"assets/lbif.wav\",\n  intensity_plotOnSpec = TRUE,\n  intensity_color = RColorBrewer::brewer.pal(3, \"Reds\")[2],\n  font.axis = 2,\n  spec_colors = RColorBrewer::brewer.pal(9, \"Greys\")[1:7],\n  font = 2,\n  pitch_freqRange = c(0, 700),\n  proportion = c(50, 25, 25),\n  family = \"fira\",\n  lwd = 2,\n  wave_color = RColorBrewer::brewer.pal(3, \"Reds\")[2],\n)\n```\n\n## Participants\n\n* Hearing, full term neonates (fNIRS) and 6-10 mo infants (fNIRS + behavioural)\n* Born/living in the Metropolitan Area of Barcelona (Spain)\n* Mostly Catalan and/or Spanish linguistic background\n\n## Stimuli\n\n* List of [SSP+]{style=\"background-color: #ea6212; color: white\"} (e.g., *blif* and [SSP-]{style=\"background-color: #781478; color: white\"} (e.g., *lbif*) CCVC syllables\n* For each syllable:\n  - Chunk acoustic signal into segments (x4 phonemes)\n  - Calculate average F0/F1/F2 of each segment\n  - Synthesise pure tone based on extracted pitch for each segment\n  - Apply amplitude envelope of original audio\n\n```{r}\nhtml_tag_audio(\"assets/enveloped_click_bran.wav\")\n```\n\n```{r}\nhtml_tag_audio(\"assets/enveloped_click_lbif.wav\")\n```\n\n## Task design (fNIRS block design)\n\n1. Test phase:\n  - 4 blocks of artificially segmented words: 1 Non-alt/[SSP+]{style=\"background-color: #ea6212; color: white\"}, 1 Non-alt/[SSP-]{style=\"background-color: #781478; color: white\"}, 2 Alt (20-22s silence between blocks)\n  - 12 words different words in each block (0.5-1.5s silence between words)\n\n---\n\n![](assets/test-ssp.png){width=100%}\n\n---\n\n## Questions\n\n- Discriminability of [SSP+]{style=\"background-color: #ea6212; color: white\"}/[SSP-]{style=\"background-color: #781478; color: white\"}: amplitude vs. pitch salience?\n    + Adult experiment, artificial neural network?\n- \n\n## {background-image=\"assets/thanks.png\"}\n\n## References\n\n\n","srcMarkdownNoYaml":""},"formats":{"prezconf-revealjs":{"identifier":{"display-name":"RevealJS","target-format":"prezconf-revealjs","base-format":"revealjs","extension-name":"prezconf"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":800,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":["_extensions/gongcastro/prezconf/logo-github.png","_extensions/gongcastro/prezconf/logo-twitter.png","_extensions/gongcastro/prezconf/logo-orcid.png","_extensions/gongcastro/prezconf/logo-sjd.png"],"shortcodes":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","filters":[],"self-contained":true,"from":"markdown+emoji","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.5.43","auto-stretch":true,"theme":"_extensions/gongcastro/prezconf/style.scss","slideNumber":"c","template-partials":["_extensions/gongcastro/prezconf/title-slide.html"],"affiliation-logo":["_extensions/gongcastro/prezconf/logo-sjd.png"],"revealjs-plugins":[],"title":"Mechanisms for parsing speech into syllables in early infancy","resources":["assets/enveloped_click_bran.wav","assets/enveloped_click_lbif.wav"],"author":[{"name":"Gonzalo García-Castro","orcid":"0000-0002-8553-4209","institute":"Neurodevelopment and Comparative Cognition group"}],"bibliography":["assets/references.bib"],"cls":"assets/apa7.csl","scrollable":true,"showSlideNumber":"all","date":"2024/09/24","conference":"padova2024mop","transition":"fade","progress":true,"preloadIframes":true,"github":"gongcastro","twitter":"gongcastro"}}},"projectFormats":["prezconf-revealjs"]}