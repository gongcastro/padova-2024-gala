```{r setup}
library(tibble)
library(tidyr)
library(ggplot2)
library(ggdist)
library(dplyr)
library(patchwork)
library(praatpicture)
library(showtext)

font_add_google("Roboto Condensed", "Roboto")
windowsFonts("Roboto Condensed" = windowsFont("Roboto Condensed"))

html_tag_audio <- function(file, type = c("wav")) {
  type <- match.arg(type)
  htmltools::tags$audio(
    controls = "",
    htmltools::tags$source(
      src = file,
      type = glue::glue("audio/{type}", type = type)
    )
  )
}

clrs <- c("#ea6212", "#ff001e", "#781478")
```


## (Why) only us?

::: columns
:::: {.column width=65%}

* Humans develop linguistic abilities unparalelled to non-human animals
* But some animals show certain ability to process some aspects of language [e.g., @toro2016something]
* Shared mechanisms: [entry gate to human language acquisition]{style="background-color: #e3e1e1;"}?

::::
:::: {.column width=35%}
[![](assets/why-only-us.jpg){width=50%}](https://mitpress.mit.edu/9780262533492/why-only-us/)
::::
:::

::: box
**Gates to Language (GALA) ERC project (Chiara Santolin)**
:::

::: {.notes}
- Most animals develop sophisticated communicative systems
- Only humans develop language (compositional, recursive, symbolic, etc.)
- Some animals show near-human-level abilities in some of those domains
- We share with non-human animals some mechanisms that support language
- Are those mechanisms the entry gate to human language acquisition?
- In this ERC-StG awareded to Chiara Santolin, we are going to investigate the possible role of two of those mechanisms on early language acquisition
:::

---

## Discrete units in the continuous speech signal

![From @meyer2018neural.](assets/multilevel.jpg)

::: {.notes}
- We are focusing on one of the first and most critical steps in language acquisition: chunking the continuous speech stream into discrete, linguistically relevant units.
:::

## The syllable: a privileged linguistic unit?

Newborns (and adults) preferentially parse the speech signal into [syllable-sized units]{style="background-color: #e3e1e1;"} [e.g, @bijeljac19934; @flo2022sleeping; @luo2007phase; @jusczyk1987representation; @bertoncini1988investigation]

![From @flo2022sleeping.](assets/entrainment.png)

::: {.notes}
- Syllables seem to be specially important during the first stages of language acquisition
- Newborns preferentially parse speech into syllables (as opposed to individual phonemes, words, or phrases)
- What makes syllables so special? 
:::

## Syllabic structure

::: {.columns}
::: {.column width="40%"}
![](assets/structure.png)
:::
::: {.column width="60%"}
:::
:::

::: {.notes}
- The universal structure of a syllable is made of three elements
- A mandatory nucleus: this is a high-sonority speech sound (predominantly a vowel)
- Perhaps an onset, made of one or more consonants
- Perhaps a coda, made of one or more consonant
:::

## Syllabic structure

::: {.columns}
::: {.column width="40%"}
![](assets/structure.png)
:::
::: {.column width="60%"}
|Structure |Onset  |Nucleus  |Coda  |
|----------|:-----:|:-------:|:----:|
| V        |       |a        |      |
| CV       | t     |a        |      |
| CVC      | t     |a        |n     |
| VC       |       |a        |n     |
:::
:::

::: {.notes}
- Same examples of syllables
:::


## Language-specific constraints to syllabic structure

| Structure | Japanese     | Spanish          | English         |
|-----------|--------------|------------------|-----------------|
|V          | [u]{style="background-color: #e3e1e1;"}.mi     | [o]{style="background-color: #e3e1e1;"}.jo         | [a]{style="background-color: #e3e1e1;"}.ny        |
|CV         | [ya]{style="background-color: #e3e1e1;"}.ma.ha | [ca]{style="background-color: #e3e1e1;"}.sa        | [fai]{style="background-color: #e3e1e1;"}.ry      | 
|CVC        | [hon]{style="background-color: #e3e1e1;"}.da   | [rin]{style="background-color: #e3e1e1;"}.cón      | [con]{style="background-color: #e3e1e1;"}.trol    |
|CCVC       |              | [fres]{style="background-color: #e3e1e1;"}.co      | [fresh]{style="background-color: #e3e1e1;"}       |
|CCVCC      |              | [trans]{style="background-color: #e3e1e1;"}.por.te | [shrink]{style="background-color: #e3e1e1;"}     |
|CCCVCCC    |              |                  | [strengths]{style="background-color: #e3e1e1;"}   |

: Adapted from Özer (2024).

::: {.notes}
- Not all syllabic structures are possible in all languages
- Some languages impose stricter phonotactical constraints on the specific sounds and number of sounds that can occur at onset or coda
:::


## Universal constraints to syllabic structure

Can you chunk this word into syllables?

> /likla/

. . .

::: box
**Maximal Onset Principle (MOP)**:

Consonants are preferably grouped at syllabic onset
:::

* [MOP+]{style="background-color: #ea6212; color: white"}: CV.CCV - /li.kla/
* [MOP-]{style="background-color: #781478; color: white"}: CVC.CV - /lik.la/

::: {.notes}
- However, some constraints to syllabic structure seem to be universal
- Universal: most, if not all languages, show a preference for following some specific constraints
- The aim of this project is to investigate the possible role of these universals as an early mechanism for syllabification
:::

## Universal constraints to syllabic structure

Which of these syllables sound good to you?

> /blif/ vs. /lbif/

. . .

::: box
**Sonority Sequencing Principle (SSP)**:

Sonority increases at onset, peaks at nucleus, decreases in coda
:::

```{r fig-ssp-blif}
#| label: fig-ssp-blif
#| fig-height: 1.5
#| fig-width: 6
tribble(
  ~position, ~phoneme, ~sonority,
  "Onset", "b", 4,
  "Onset", "l", 10,
  "Nucleus", "i", 17,
  "Coda", "f", 7
) |>
  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>
  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +
  geom_col(colour = "white") +
  geom_line(aes(group = 1)) +
  geom_point(show.legend = FALSE) +
  tribble(
    ~position, ~phoneme, ~sonority,
    "Onset", "l", 10,
    "Onset", "b", 4,
    "Nucleus", "i", 15,
    "Coda", "f", 7
  ) |>
  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>
  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +
  geom_col(colour = "white") +
  geom_line(aes(group = 1)) +
  geom_point(show.legend = FALSE) +
  theme(axis.title.y = element_blank()) +
  plot_layout(nrow = 1, guides = "collect") &
  labs(x = "Phoneme", y = "Sonority Index") &
  scale_fill_manual(values = clrs) &
  theme_ggdist(base_family = windowsFonts()$`Roboto Condensed`) &
  theme(
    legend.position = "right",
    axis.title.x = element_blank(),
    legend.title = element_blank(),
    plot.background = element_rect(fill = NA)
  )
```

::: {.notes}
- However, some constraints to syllabic structure seem to be universal
- Universal: most, if not all languages, show a preference for following some specific constraints
- Both universals determine to a large extent the position of syllabic boundaries, and the order of the segments that make up a syllable
:::



## The Gates to Language (GALA) project

* Do newborns use MOP and SSP to detect syllable boundaries?

> Syllables as an entry gate to language

. . .

* Are these mechanisms shared with non-human animals? (e.g., production)

> Syllables as philogenetically relevant linguistic units

. . .


::: {.notes}
- The aim of this project is to investigate:
  1) The possible role of these universals as an early mechanism for syllabification
  2) The extent to which these mechanisms are shared with other non-human animals
- The Maximal Onset Principle (MOP) and the Sonority Sequencing Principle (SSP)
- We will also investigate whether a non-human animal species (Long-Evans rats), which do not develop language, are also sensitive to any of these principles
:::

## The Gates to Language (GALA) project

Two lines of research: MOP and SSP

* Neonates (fNIRS)
* Infants (fNIRS, eye-tracking, behaviour)
* Adults (behavioural)
* Long-Evans rats (behavioural)


# Maximal Onset Principle (MOP)

Research line 1

## Study 1: are newborns sensitive to (violations of) the MOP?

::: box
Consonants are preferably grouped at syllable onset.
:::

* [MOP+]{style="background-color: #ea6212; color: white"}: CV.CCV - /li.kla/  
* [MOP-]{style="background-color: #781478; color: white"}: CVC.CV - /lik.la/

::: {.notes}
- The first universal we will investigate is the Maximal Onset Principle (MOP)
- This principle states that "consonants" are preferably grouped at syllable onset
- This principle constrains the position of syllabic boundaries
- If neonates are sensitive to violations of the MOP, it would suggest that they might be using the MOP to syllabify the speech signal from birth
:::


## Participants

* Hearing, full term neonates (fNIRS) and 6-10 mo infants (fNIRS + behavioural)
* Born/living in the Metropolitan Area of Barcelona (Spain)
* Mostly Catalan and/or Spanish linguistic background

::: {.notes}
- We will run an experimental series that involves neonates and infants
- Neonates will be tested using fNIRS, while infants will be tested using fNIRS and behavioural tasks (like the HeadTurn Preference Procedure)
- I will focus on the fNIRS testing of neonates and infants, as they follow the same task design
- Ideally, we'd like to test up to 50 participants per experiment, although power analysis is pending
- Most of our participants will have a Catalan and/or Spanish background
:::


## fNIRS setup

* NIRSport2 (NIRx), CW 760 nm & 850 nm
* Sampling frequency 20.345 Hz (~0.05 s samples)
* NIRScap: 8 channels LH, 8 channels RH
* ROIs: L and R temporal regions
* Crib testing in neonates, parents' lap in infants (watching cartoons)
* MNE-NIRS (Python): (1) OD, (2) motion correction (TDDR), (3) band-pass filtering, (4) block segmentation, (5) block averaging, (6) block rejection, (7) participant rejection.

## Task design (fNIRS block design)

**Familiarisation/discrimination task:**

1) Familiarise participants with disyllabic CVCCV words
    - 10 blocks, 6 words each

. . .

2) Test discrimination of artificially segmented familiar words as [MOP+]{style="background-color: #ea6212; color: white"} (CV.CCV) vs. [MOP-]{style="background-color: #781478; color: white"} (CVC.CV):
    - 4 alternating blocks ([MOP+]{style="background-color: #ea6212; color: white"}/[MOP-]{style="background-color: #781478; color: white"})
    - 2 non-alternating blocks ([MOP+]{style="background-color: #ea6212; color: white"})
    - 2 non-alternating blocks ([MOP-]{style="background-color: #781478; color: white"})

## Stimuli

::: box
**CVCCV words**: Onset + Vowel + Consonant cluster (CC) + Vowel
:::

. . .

::: columns
:::: {.column width="40%"}
| [MOP+]{style="background-color: #ea6212; color: white"} (CV.CCV) | [MOP-]{style="background-color: #781478; color: white"} (CVC.CV)|
|:-------------:|:------------:|
|li.kla         |lik.la        |
|ro.tri         |rot.ri        |
|po.glu         |pog.lu        |

::::
:::: {.column width="60%"}
Some constraints:

- [MOP+]{style="background-color: #ea6212; color: white"}: CC follows **SSP**
- [MOP+]{style="background-color: #ea6212; color: white"}: CC is phonotactical at onset in speakers' and participants' native language(s)
- [MOP-]{style="background-color: #781478; color: white"}: C is allowed in coda in speakers' and participants' native language(s)
::::
:::

---

### Familiarisation phase

![](assets/fam-mop.png){width=100%}

---

### Test phase

![](assets/test-mop.png){width=100%}

## Questions

- Natural speaker or synthesised speech (e.g., MBROLA)?
- Variability vs. repetition? More vs. less consonant clusters
- Linguistic experience at 8-12 months?
- Familiarisation phase: how many blocks is enough/too much?
- fNIRS recording during familiarisation? (e.g., capping in between phases)

# Sonority Sequencing Principle (SSP)

Research line 2

## Study 2: are newborns sensitive to (violations of) the SSP?

::: columns
:::: {.column width="40%" .incremental}

Syllables are predominantly a production unit: they result from a "single effort or impulse of the voice." [@whitney1874oriental]

> In a syllable, sonority increases toward the peak and decreases toward the margins. [@morelli2003relative]

::::
:::: {.column width="60%"}
The biomecanics of the phonatory system constrain the properties of the acoustic signal of (exhalated) animal vocalisations.

![From @tierney2011motor](assets/birds.png)
::::
:::



## Study 2: are newborns sensitive to (violations of) the SSP?

[Proposal]{style="background-color: #e3e1e1;"}:

1) Syllables are biologically relevant linguistic units
2) Language processing at birth is constrained by phylogenetically acquired perception mechanisms (e.g., SSP)

. . .

[Hypotheses]{style="background-color: #e3e1e1;"}:

* Neonates are sensitive to (violations of) the SSP
* Long-Evans rats are sensitive to (violations of) the SSP
* This sensitivity plays a role beyond language (non-linguistic sounds)

---

```{r fig-ssp-bran}
#| label: fig-ssp-bran
#| fig-cap: "Sonority Sequencing Principle. Sonority values from @parker201149"
#| fig-height: 4
#| fig-width: 6
tribble(
  ~position, ~phoneme, ~sonority,
  "Onset", "b", 1,
  "Onset", "ɾ", 10,
  "Nucleus", "a", 17,
  "Coda", "n", 7
) |>
  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>
  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +
  geom_col(colour = "white") +
  geom_line(aes(group = 1)) +
  geom_point(show.legend = FALSE) +
  labs(x = "Phoneme", y = "Sonority Index") +
  scale_fill_manual(values = clrs) +
  theme_ggdist() +
  theme(
    legend.position = "top",
    axis.title.x = element_blank(),
    legend.title = element_blank(),
    plot.background = element_rect(fill = NA)
  )
```

## Sonority Sequencing Principle (SSP)

```{r fig-ssp-bran-grid}
#| label: fig-sspl-bran-grid
#| fig-cap: "Sonority profile of the syllable 'bran'"
praatpicture::praatpicture(
  "assets/bran.wav",
  intensity_plotOnSpec = TRUE,
  intensity_color = clrs[1],
  font.axis = 2,
  spec_colors = RColorBrewer::brewer.pal(9, "Greys")[1:7],
  font = 2,
  pitch_freqRange = c(0, 700),
  proportion = c(50, 25, 25),
  family = "fira",
  lwd = 2,
  wave_color = clrs[1],
)
```

## Sonority Sequencing Principle (SSP)

```{r fig-ssp-lbif}
#| label: fig-ssp-lbif
#| fig-cap: "Sonority Sequencing Principle. Sonority values from @parker201149"
tribble(
  ~position, ~phoneme, ~sonority,
  "Onset", "l", 9,
  "Onset", "b", 1,
  "Nucleus", "i", 15,
  "Coda", "f", 3
) |>
  mutate(phoneme = factor(phoneme, levels = phoneme, ordered = TRUE)) |>
  ggplot(aes(phoneme, sonority, fill = reorder(position, desc(position)))) +
  geom_col(colour = "white") +
  geom_line(aes(group = 1)) +
  geom_point(show.legend = TRUE) +
  labs(x = "Phoneme", y = "Sonority Index") +
  scale_fill_manual(values = clrs) +
  theme_ggdist() +
  theme(
    legend.position = "top",
    axis.title.x = element_blank(),
    legend.title = element_blank(),
    plot.background = element_rect(fill = NA)
  )
```

## Sonority Sequencing Principle (SSP)

```{r fig-ssp-lbif-grid}
#| label: fig-sspl-lbif-grid
#| fig-cap: "Sonority profile of the syllable 'lbif'"
praatpicture::praatpicture(
  "assets/lbif.wav",
  intensity_plotOnSpec = TRUE,
  intensity_color = clrs[1],
  font.axis = 2,
  spec_colors = RColorBrewer::brewer.pal(9, "Greys")[1:7],
  font = 2,
  pitch_freqRange = c(0, 700),
  proportion = c(50, 25, 25),
  family = "fira",
  lwd = 2,
  wave_color = clrs[1],
)
```

## Participants

* Hearing, full term neonates (fNIRS) and 6-10 mo infants (fNIRS + behavioural)
* Born/living in the Metropolitan Area of Barcelona (Spain)
* Mostly Catalan and/or Spanish linguistic background

## Stimuli

From @schutsch2024sensory:

* List of [SSP+]{style="background-color: #ea6212; color: white"} (e.g., *blif* and [SSP-]{style="background-color: #781478; color: white"} (e.g., *lbif*) CCVC syllables
* For each syllable:
  - Chunk acoustic signal into segments (x4 phonemes)
  - Calculate average F0/F1/F2 of each segment
  - Synthesise pure tone based on extracted pitch for each segment
  - Apply amplitude envelope of original audio

```{r}
html_tag_audio("assets/enveloped_click_bran.wav")
```

```{r}
html_tag_audio("assets/enveloped_click_lbif.wav")
```

## Task design (fNIRS block design)

1. Test phase:
  - 4 blocks of artificially segmented words: 1 Non-alt/[SSP+]{style="background-color: #ea6212; color: white"}, 1 Non-alt/[SSP-]{style="background-color: #781478; color: white"}, 2 Alt (20-22s silence between blocks)
  - 12 words different words in each block (0.5-1.5s silence between words)

---

![](assets/test-ssp.png){width=100%}

---

## Questions

- Discriminability of [SSP+]{style="background-color: #ea6212; color: white"}/[SSP-]{style="background-color: #781478; color: white"}: amplitude vs. pitch salience?
    + Adult experiment, artificial neural network?
    
## {background-image="assets/thanks.png"}

## References


